The previous section has done preliminary work to show that it may be possible to incorporate explicit ethical components into a machine in specific domains.\ Ensuring that a machine with such components can function autonomously in the real world is still a challenge for AI researchers. 

\indent In Step 1 of the previous section, adopting a prima-facie duty approach, resembles stating mathematical axioms which are assumed to be true, to serve as a premise for further reasoning and arguments.\ If the analogy is right, is this a correct approach or are there a better ways for representing domain-specific ethical principles?\ Mathematical axioms establish a formal system upon which mathematical logic is built and is used for inferences and theorem proving.\ Hence, if a formal system is needed for representing ethical principles, like prima-facie duties, then this seems to be a reasonable approach.\ Beauchamp and Childress \cite{beauchamp2001principles} coined the four biomedical ethical principles which Anderson et al.\ implemented.\ So the question, who decides these prima-facie duties -- trained domain-ethicists or all stakeholders inlcuded remains.

\indent Anderson et al.\ \cite{Anderson_Anderson_2007} discussed a dilemma type where three duties among the four conflicted. But how to find that particular subset?\ And even if we know the relevant duties that might conflict, how can we teach them to the agent in new case profiles?\ A reinforcement learning framework, as a viable approach to find and teach these relevant duties to the agent, is explained in Section 6.

\indent In Step 4 of the previous section, a formal system of ILP using prima-facie duties and logic programming was used.\ No doubt it captures the complex, non-classical relationships between the duties; tests the consistency of the hypothesis learned from the previous cases; and develops a common-sense background knowledge regarding the updated hypotheses.\ But is there any other technology that has similar characteristics and performs better and more efficient than ILP?

\indent Anderson et al.\ \cite{Anderson_Anderson_2007} validated their proof of concept by building advisory and recommender agents which interacted with human users, collected data by asking questions and converting them into profiles, putting them through the learning algorithm and finally giving a decision.\ Whether this is the only way to validate our concepts can be debatable. If no, what are possible reasons for its success? \\
\indent In the last step, evaluation using cMTT by comparing results with a trained ethicist was proposed.\ The last question is whether only trained ethicists are enough, given their scarcity in this world, or should we include all stakeholders, or mixed groups of trained ethicists and stakeholders?